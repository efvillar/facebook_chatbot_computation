{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOT DE COMPUTACION SEQ2SEQ\n",
    "Este chatbot se construyó con datos de la pgágina web www.elforo.net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./data/elforo/elforo.json',encoding=\"utf-8\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n"
     ]
    }
   ],
   "source": [
    "#lista de preguntas\n",
    "preguntas = list()\n",
    "for key in data:\n",
    "    preguntas.append(key)\n",
    "\n",
    "print (len(preguntas))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bien. Pues tras las explicaciones de Roberto0, en Religión, y las de Gabin, en Quejas, hemos podido comprobar que se puede escribir con tildes y Ñ. O sea, con los carácteres españoles. Y también se puede copiar y pegar fácilmente sin usar comandos.Y da igual el editor que se tenga configurado en el foro, es decir, ya sea el básico, el estándar o el avanzado.Recuerden:- Bajamos abajo de la página, a la izquierda y le damos al desplegable donde sale la versión elegible del foro, \"-- vB4 Default Style\".- Le damos a la versión para móviles, \"Default Mobile Style\". - Saldrá una nueva vista del foro. Le damos a un cuadradito arriba a la derecha y veremos varias opciones. - Pinchamos en Foros y ahí podremos escribir con tildes y Ñ.Luego, si queremos volver a la versión anterior para leerla cómo siempre, nos vamos abajo en el centro y pinchamos \"Full Site\".Gracias mil a Roberto0 y a Gabin!! \n"
     ]
    }
   ],
   "source": [
    "print (preguntas[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de respuestas\n",
    "respuestas = list()\n",
    "i=0\n",
    "for key in data:\n",
    "    try:\n",
    "        temp1 = data[key][0]\n",
    "    except:\n",
    "        temp1 = \"No entiendo\"\n",
    "    respuestas.append(temp1)\n",
    "    #print (data[key][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n"
     ]
    }
   ],
   "source": [
    "print (len(respuestas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, A ver, mi opinion:Una pregunta: Trabajas JAVA en tu device?, si la respuesta es si, podrias tener eventualmente el fichero Eclipse.exe instalado en el Sistema.Cuando Windows Defender hace un escaneo,  se topa con Eclipse.exe y como el fichero esta escrito en JAVA  hace dificil hacer un escaneo.en forma fluida.Eclipse.exe se ubica en una subcarpeta de la carpeta de perfil del usuario (tu, en este caso…), y el PAD de ubicación es C: \\ Users \\ USERNAME \\ eclipse \\ php-mars \\ eclipse \\.El volumen de este file es de unos  312 MB  o mas y podria eventualmente ser eliminado, para probar si esto soluciona el problema.  (luego,  podria ser tambien reinstalado, para el Sistema Operativo que tu tiene, que a proposito, no lo has mencionado !!). Si ese fuese el problema, lo que sucede es que Eclipse.exe, esta escrito en JAVA y ello, demoraria el escaneo del programa (WD). Yo no uso Windowes Defender, pues, AVAST-Pro, hace de acuerdo a mi criterio, un trabajo exelente en los divaces. .No olvides jamas, hacer un backup, antes de enfrentar un problema como este,\n"
     ]
    }
   ],
   "source": [
    "print (respuestas[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [re.sub(r\"\\[\\w+\\]\",'hola',line) for line in preguntas]  #quitar palabras en brakets\n",
    "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]  #para quitar paginas web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bien Pues tras las explicaciones de Roberto0 en Religión y las de Gabin en Quejas hemos podido comprobar que se puede escribir con tildes y Ñ O sea con los carácteres españoles Y también se puede copiar y pegar fácilmente sin usar comandos Y da igual el editor que se tenga configurado en el foro es decir ya sea el básico el estándar o el avanzado Recuerden Bajamos abajo de la página a la izquierda y le damos al desplegable donde sale la versión elegible del foro vB4 Default Style Le damos a la versión para móviles Default Mobile Style Saldrá una nueva vista del foro Le damos a un cuadradito arriba a la derecha y veremos varias opciones Pinchamos en Foros y ahí podremos escribir con tildes y Ñ Luego si queremos volver a la versión anterior para leerla cómo siempre nos vamos abajo en el centro y pinchamos Full Site Gracias mil a Roberto0 y a Gabin'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines2 = [re.sub(r\"\\[\\w+\\]\",' ',line) for line in respuestas]\n",
    "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in respuestas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' «Thou wilt keep him in perfect peace, whose mind is stayed on thee: because he trusteth in thee». – Isaiah 26:3'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuestas[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de tuplas pregunta y respuesta\n",
    "pairs = list(zip(lines,lines2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mi computadora no funciona variadas veces el internet que puedo hacer',\n",
       "  'Marca Desktop Laptop y Sistema Operativo MEM instalada'),\n",
       " ('Hace días me saludó Martucha y me preguntó por el Foro a mi me encantaría que viniera a contarnos sus historias',\n",
       "  'Pensar por cuenta propia GBNL'),\n",
       " ('Buen día Quiero grabar la pantalla de mi new nintendo 3ds xl ya hackeada con B9S yo uso linux basado en ubuntu Alguien me puede ayudar a lograrlo',\n",
       "  'Hola Un tema con detalles de algo hackeado es algo que aqui no se asiste')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "for line in pairs[:400]:\n",
    "  input_doc, target_doc = line[0], line[1]\n",
    "  # Appending each input sentence to input_docs\n",
    "  input_docs.append(input_doc)\n",
    "  # Splitting words from punctuation  \n",
    "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "  # Redefine target_doc below and append it to target_docs\n",
    "  target_doc = '<START> ' + target_doc + ' <END>'\n",
    "  target_docs.append(target_doc)\n",
    "     # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
    "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "    if token not in input_tokens:\n",
    "      input_tokens.add(token)\n",
    "  for token in target_doc.split():\n",
    "    if token not in target_tokens:\n",
    "      target_tokens.add(token)\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> No entiendo <END>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '00', '000', '000Les', '001']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '00', '000', '0WLAN', '1']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10091, 3419)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1559, 427)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoder_seq_length, max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(input_docs), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "    \n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "        if timestep > 0:\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1559, 10091)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 3419)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hace días me saludó Martucha y me preguntó por el Foro a mi me encantaría que viniera a contarnos sus historias', 'Pensar por cuenta propia GBNL'), ('Buen día Quiero grabar la pantalla de mi new nintendo 3ds xl ya hackeada con B9S yo uso linux basado en ubuntu Alguien me puede ayudar a lograrlo', 'Hola Un tema con detalles de algo hackeado es algo que aqui no se asiste')]\n",
      "['Hace días me saludó Martucha y me preguntó por el Foro a mi me encantaría que viniera a contarnos sus historias', 'Buen día Quiero grabar la pantalla de mi new nintendo 3ds xl ya hackeada con B9S yo uso linux basado en ubuntu Alguien me puede ayudar a lograrlo']\n"
     ]
    }
   ],
   "source": [
    "decoder_target_data[4]\n",
    "print(pairs[1:3])\n",
    "print(input_docs[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7475 - accuracy: 0.0198 "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "#Dimensionality\n",
    "dimensionality = 256\n",
    "#The batch size and number of epochs\n",
    "batch_size = 5\n",
    "epochs = 5\n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#Model\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "#Compiling\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "#Training\n",
    "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "training_model.save('training_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "training_model = load_model('training_model.h5')\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_response(test_input):\n",
    "    #Getting the output states to pass into the decoder\n",
    "    states_value = encoder_model.predict(test_input)\n",
    "    #Generating empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    #Setting the first token of target sequence with the start token\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "    \n",
    "    #A variable to store our response word by word\n",
    "    decoded_sentence = ''    \n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "      #Predicting output tokens with probabilities and states\n",
    "      output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "#Choosing the one with highest probability\n",
    "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "      sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "      decoded_sentence += \" \" + sampled_token\n",
    "#Stop if hit max length or found the stop token\n",
    "      if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "        stop_condition = True\n",
    "#Update the target sequence\n",
    "      target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "      target_seq[0, 0, sampled_token_index] = 1.\n",
    "      #Update states\n",
    "      states_value = [hidden_state, cell_state]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
    "#Method to start the conversation\n",
    "  def start_chat(self):\n",
    "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
    "    \n",
    "    if user_response in self.negative_responses:\n",
    "      print(\"Ok, have a great day!\")\n",
    "      return\n",
    "    self.chat(user_response)\n",
    "#Method to handle the conversation\n",
    "  def chat(self, reply):\n",
    "    while not self.make_exit(reply):\n",
    "      reply = input(self.generate_response(reply)+\"\\n\")\n",
    "    \n",
    "  #Method to convert user input into a matrix\n",
    "  def string_to_matrix(self, user_input):\n",
    "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "    user_input_matrix = np.zeros(\n",
    "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
    "      dtype='float32')\n",
    "    for timestep, token in enumerate(tokens):\n",
    "      if token in input_features_dict:\n",
    "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "    return user_input_matrix\n",
    "  \n",
    "  #Method that will create a response using seq2seq model we built\n",
    "  def generate_response(self, user_input):\n",
    "    input_matrix = self.string_to_matrix(user_input)\n",
    "    chatbot_response = decode_response(input_matrix)\n",
    "    #Remove <START> and <END> tokens from chatbot_response\n",
    "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
    "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
    "    return chatbot_response\n",
    "#Method to check for exit commands\n",
    "  def make_exit(self, reply):\n",
    "    for exit_command in self.exit_commands:\n",
    "      if exit_command in reply:\n",
    "        print(\"Ok, have a great day!\")\n",
    "        return True\n",
    "    return False\n",
    "  \n",
    "chatbot = ChatBot()\n",
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.start_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
